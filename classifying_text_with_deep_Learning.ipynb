{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GbygQ8NCrlihNlaKGmP_12QGZkNP4ToE",
      "authorship_tag": "ABX9TyMdORYvEQHtCyTePxNQTfud",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazirumar/NLP/blob/main/classifying_text_with_deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recipe 6-2. Classifying Text with Deep\n",
        "Learning**\n",
        "\n",
        "In this recipe, let us build a text classifier using deep learning approaches.\n",
        "\n",
        "**Problem**\n",
        "\n",
        "We want to build a text classification model using CNN, RNN, and LSTM.\n",
        "\n",
        "**Solution**\n",
        "\n",
        "The approach and NLP pipeline would remain the same as discussed\n",
        "earlier. The only change would be that instead of using machine learning\n",
        "algorithms, we would be building models using deep learning algorithms.\n",
        "\n",
        "**How It Works**\n",
        "\n",
        "Let’s follow the steps in this section to build the email classifier using the\n",
        "deep learning approaches."
      ],
      "metadata": {
        "id": "01FEI-4E2MdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2-1 Understanding/defining business problem**\n",
        "\n",
        "Email classification (spam or ham). We need to classify spam or ham email\n",
        "based on email content"
      ],
      "metadata": {
        "id": "5FO8e0w_2qcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2-2 Identifying potential data sources, collection,\n",
        "and understanding**\n",
        "\n",
        "Using the same data used in Recipe 4-6 from Chapter 4:"
      ],
      "metadata": {
        "id": "LjjQMEGP2te0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "cW0XJ1ZU291B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "VTRprFKf07-G",
        "outputId": "d2b17940-dec2-4b6d-d383-40cfc6a7db99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        v1                                                 v2 Unnamed: 2  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "...    ...                                                ...        ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
              "5571   ham                         Rofl. Its true to its name        NaN   \n",
              "\n",
              "     Unnamed: 3 Unnamed: 4  \n",
              "0           NaN        NaN  \n",
              "1           NaN        NaN  \n",
              "2           NaN        NaN  \n",
              "3           NaN        NaN  \n",
              "4           NaN        NaN  \n",
              "...         ...        ...  \n",
              "5567        NaN        NaN  \n",
              "5568        NaN        NaN  \n",
              "5569        NaN        NaN  \n",
              "5570        NaN        NaN  \n",
              "5571        NaN        NaN  \n",
              "\n",
              "[5572 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39bad8d8-a820-4117-8df1-1e63a25a25c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39bad8d8-a820-4117-8df1-1e63a25a25c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39bad8d8-a820-4117-8df1-1e63a25a25c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39bad8d8-a820-4117-8df1-1e63a25a25c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#rea file\n",
        "file_content = pd.read_csv('/content/drive/MyDrive/NLP/spam.csv', encoding='latin-1')\n",
        "file_content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2-3 Text preprocessing**\n",
        "\n",
        "Let’s preprocess the data:\n",
        "\n",
        "*Import library*"
      ],
      "metadata": {
        "id": "EszabTvN4DGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EekYrcmF2oUf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Remove stopwords*"
      ],
      "metadata": {
        "id": "c6bgOwsJ4OsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop = stopwords.words('english')\n",
        "file_content['v2'] = file_content['v2'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a4Jw-A9M4OKI",
        "outputId": "a97bcafc-46d0-4836-cb21-03119be79549"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-aea56c953ae2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reKY-ezZ4Vav",
        "outputId": "ec803f3f-6d56-432c-fd06-2907c0b43f3e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Delete unwanted columns*"
      ],
      "metadata": {
        "id": "yWTJr-4t4dIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Email_Data = file_content[['v1', 'v2']]"
      ],
      "metadata": {
        "id": "f5-pGW1V4ZJz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Rename column names*"
      ],
      "metadata": {
        "id": "ubB6spGK4iW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Email_Data = Email_Data.rename(columns={\"v1\":\"Target\", \"v2\":\"Email\"})\n",
        "Email_Data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "apf-Pvtv4gWu",
        "outputId": "d4ff39dd-333b-40c2-8108-826fdee6596a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Target                                              Email\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f479a8bb-5b8e-426d-baa7-ed620812cf76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Email</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f479a8bb-5b8e-426d-baa7-ed620812cf76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f479a8bb-5b8e-426d-baa7-ed620812cf76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f479a8bb-5b8e-426d-baa7-ed620812cf76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Delete punctuations, convert text in lower case and delete the\n",
        "double space*"
      ],
      "metadata": {
        "id": "mLXqcRGo4pQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Email_Data['Email'] = Email_Data['Email'].apply(lambda x:\n",
        "re.sub('[!@#$:).;,?&]', '', x.lower()))\n",
        "Email_Data['Email'] = Email_Data['Email'].apply(lambda x:\n",
        "re.sub(' ', ' ', x))\n",
        "Email_Data['Email'].head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGzGBCuP4mPJ",
        "outputId": "cbcc4449-ad19-4580-fef7-3a714f690815"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    go until jurong point crazy available only in ...\n",
              "1                              ok lar joking wif u oni\n",
              "2    free entry in 2 a wkly comp to win fa cup fina...\n",
              "3          u dun say so early hor u c already then say\n",
              "4    nah i don't think he goes to usf he lives arou...\n",
              "Name: Email, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Separating text(input) and target classes*"
      ],
      "metadata": {
        "id": "TFc_IpxO44Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_sentences_rawdata = Email_Data[\"Email\"].fillna(\"_na_\").values\n",
        "list_classes = [\"Target\"]\n",
        "target = Email_Data[list_classes].values\n",
        "To_Process=Email_Data[['Email', 'Target']]"
      ],
      "metadata": {
        "id": "64eQDPXV40IH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2-4 Data preparation for model building**\n",
        "\n",
        "*Now we prepare the data*:"
      ],
      "metadata": {
        "id": "O45brigq4-_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*Train and test split with 80:20 ratio*\n"
      ],
      "metadata": {
        "id": "fshIJMD38xx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(To_Process, test_size=0.2)"
      ],
      "metadata": {
        "id": "Ss3bF8FX8u5W"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*Define the sequence lengths, max number of words and\n",
        "embedding dimensions*\n",
        "\n",
        "*Sequence length of each sentence. If more, truncate. If less,\n",
        "pad with zeros*"
      ],
      "metadata": {
        "id": "WAIohjDc5HVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 300\n"
      ],
      "metadata": {
        "id": "TDGFqK8x48h1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 20000 frequently occurring words**"
      ],
      "metadata": {
        "id": "_JNSP8LT5idw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_NB_WORDS = 20000"
      ],
      "metadata": {
        "id": "qB-BpRxN5h3I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the frequently occurring words**"
      ],
      "metadata": {
        "id": "psX0wiCo56Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(train.Email)\n",
        "train_sequences = tokenizer.texts_to_sequences(train.Email)\n",
        "test_sequences = tokenizer.texts_to_sequences(test.Email)"
      ],
      "metadata": {
        "id": "IBlE6p2g549e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*dictionary containing words and their index*"
      ],
      "metadata": {
        "id": "wDjkA1eG9xzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "# print(tokenizer.word_index)\n",
        "# total words in the corpus\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vo7cWm-834w",
        "outputId": "7461bbd3-9482-4528-faa1-dbbd1f8ea73f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8389 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get only the top frequent words on train\n",
        "train_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "id": "OINR7Ex197MV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get only the top frequent words on test\n",
        "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "id": "4UlK242_99qc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRMPEb09-U-m",
        "outputId": "27f7d62b-ad80-49d0-e06e-7a9254bb6396"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4457, 300)\n",
            "(1115, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train['Target']\n",
        "test_labels = test['Target']"
      ],
      "metadata": {
        "id": "GnqJ2Rg6-cqq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "\n",
        "train_labels = le.transform(train_labels)\n",
        "test_labels = le.transform(test_labels)\n",
        "\n",
        "print(le.classes_)\n",
        "print(np.unique(train_labels, return_counts=True))\n",
        "print(np.unique(test_labels, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s9k5LFZ-jZN",
        "outputId": "aa3810da-23e2-4961-b986-d7fd41099ac1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ham' 'spam']\n",
            "(array([0, 1]), array([3860,  597]))\n",
            "(array([0, 1]), array([965, 150]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing data types\n",
        "labels_train = to_categorical(np.asarray(train_labels))\n",
        "labels_test = to_categorical(np.asarray(test_labels))\n",
        "print('Shape of data tensor:', train_data.shape)\n",
        "print('Shape of label tensor:', labels_train.shape)\n",
        "print('Shape of label tensor:', labels_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAbWU7_h_V5D",
        "outputId": "21b16fc6-fcb4-47b2-a50f-64b03f9085bd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (4457, 300)\n",
            "Shape of label tensor: (4457, 2)\n",
            "Shape of label tensor: (1115, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "print(MAX_SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkTYIJ31_qSL",
        "outputId": "d7ab636b-4c0f-4d99-b5d7-db6c2cab998d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2-5 Model building and predicting**\n",
        "\n",
        "\n",
        "*We are building the models using different deep learning approaches\n",
        "like CNN, RNN, LSTM, and Bidirectional LSTM and comparing the\n",
        "performance of each model using different accuracy metrics.\n",
        "We can now define our CNN model.\n",
        "Here we define a single hidden layer with 128 memory units. The\n",
        "network uses a dropout with a probability of 0.5. The output layer is a\n",
        "dense layer using the softmax activation function to output a probability\n",
        "prediction*"
      ],
      "metadata": {
        "id": "Ln_iJNlU_uDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D,Conv1D, SimpleRNN\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.layers import Dense, Input, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "kYbAWbww_th8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training CNN 1D model.')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS,\n",
        " EMBEDDING_DIM,\n",
        " input_length=MAX_SEQUENCE_LENGTH\n",
        " ))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        " optimizer='rmsprop',\n",
        " metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGvxNWTeACpw",
        "outputId": "44703835-f2e2-430b-c4e3-58760cfc2bcb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN 1D model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We are now fitting our model to the data. Here we have 5 epochs and a\n",
        "batch size of 64 patterns.*"
      ],
      "metadata": {
        "id": "AkxiAXpYA4Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, labels_train,\n",
        " batch_size=64,\n",
        " epochs=5,\n",
        " validation_data=(test_data, labels_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2wcaA32Aqoj",
        "outputId": "2902f60c-4097-4425-bc19-5a05a0bedb5c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "70/70 [==============================] - 23s 298ms/step - loss: 0.3977 - acc: 0.8432 - val_loss: 0.4041 - val_acc: 0.8655\n",
            "Epoch 2/5\n",
            "70/70 [==============================] - 24s 337ms/step - loss: 0.1681 - acc: 0.9453 - val_loss: 0.3587 - val_acc: 0.8655\n",
            "Epoch 3/5\n",
            "70/70 [==============================] - 20s 291ms/step - loss: 0.0776 - acc: 0.9791 - val_loss: 0.4749 - val_acc: 0.8987\n",
            "Epoch 4/5\n",
            "70/70 [==============================] - 25s 358ms/step - loss: 0.0488 - acc: 0.9861 - val_loss: 0.6751 - val_acc: 0.5067\n",
            "Epoch 5/5\n",
            "70/70 [==============================] - 25s 365ms/step - loss: 0.0411 - acc: 0.9899 - val_loss: 0.6011 - val_acc: 0.9722\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabfb77b7c0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions on test data\n",
        "predicted=model.predict(test_data)\n",
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjThVFwBBUGd",
        "outputId": "c0d75dc4-c4eb-4adb-89f4-cfb7b97ab67e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 1s 30ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.54133695, 0.45866308],\n",
              "       [0.54365015, 0.4563498 ],\n",
              "       [0.34789062, 0.6521094 ],\n",
              "       ...,\n",
              "       [0.5350634 , 0.4649366 ],\n",
              "       [0.5396483 , 0.4603517 ],\n",
              "       [0.53957343, 0.46042654]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "import sklearn\n",
        "from sklearn.metrics import precision_recall_fscore_support as score"
      ],
      "metadata": {
        "id": "r-TqsrhvBa0r"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = score(labels_test,\n",
        "predicted.round())\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))\n",
        "print(\"############################\")\n",
        "print(sklearn.metrics.classification_report(labels_test,\n",
        "predicted.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVNrRBOHBl_o",
        "outputId": "ede931df-e021-4cd2-dff9-b97e18520248"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: [0.96981891 0.99173554]\n",
            "recall: [0.99896373 0.8       ]\n",
            "fscore: [0.9841756  0.88560886]\n",
            "support: [965 150]\n",
            "############################\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       965\n",
            "           1       0.99      0.80      0.89       150\n",
            "\n",
            "   micro avg       0.97      0.97      0.97      1115\n",
            "   macro avg       0.98      0.90      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            " samples avg       0.97      0.97      0.97      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can now define our RNN model**"
      ],
      "metadata": {
        "id": "SC0FlJ5IB6dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import library\n",
        "from keras.layers import SimpleRNN"
      ],
      "metadata": {
        "id": "EC5cYQY9B_Wj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model training\n",
        "print('Training SIMPLERNN model.')\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS,\n",
        " EMBEDDING_DIM,\n",
        " input_length=MAX_SEQUENCE_LENGTH\n",
        " ))\n",
        "model.add(SimpleRNN(2, input_shape=(None,1)))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "optimizer='adam',metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHt9dRi0CPGD",
        "outputId": "6ac48a21-585d-408f-cfb5-aa3ef59dad93"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SIMPLERNN model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, labels_train,\n",
        " batch_size=16,\n",
        " epochs=5,\n",
        " validation_data=(test_data, labels_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsYtTS1BCY6g",
        "outputId": "7dfc04cc-6757-49ca-c6c3-b71a39d7526d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "279/279 [==============================] - 41s 133ms/step - loss: 0.4812 - accuracy: 0.9365 - val_loss: 0.3484 - val_accuracy: 0.9731\n",
            "Epoch 2/5\n",
            "279/279 [==============================] - 28s 100ms/step - loss: 0.2440 - accuracy: 0.9861 - val_loss: 0.2193 - val_accuracy: 0.9749\n",
            "Epoch 3/5\n",
            "279/279 [==============================] - 28s 100ms/step - loss: 0.1399 - accuracy: 0.9926 - val_loss: 0.1633 - val_accuracy: 0.9776\n",
            "Epoch 4/5\n",
            "279/279 [==============================] - 33s 120ms/step - loss: 0.0919 - accuracy: 0.9971 - val_loss: 0.1306 - val_accuracy: 0.9758\n",
            "Epoch 5/5\n",
            "279/279 [==============================] - 43s 155ms/step - loss: 0.0655 - accuracy: 0.9987 - val_loss: 0.1152 - val_accuracy: 0.9731\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabfc1bb760>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction on test data\n",
        "predicted_Srnn=model.predict(test_data)\n",
        "predicted_Srnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsx21dRtChhq",
        "outputId": "c8d1b21f-1ccd-43fe-f999-26d46a86c48a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 1s 15ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9112761e-01, 8.8724168e-03],\n",
              "       [9.9896932e-01, 1.0306175e-03],\n",
              "       [3.8694527e-02, 9.6130544e-01],\n",
              "       ...,\n",
              "       [9.9734265e-01, 2.6574109e-03],\n",
              "       [9.9432892e-01, 5.6710988e-03],\n",
              "       [9.9906796e-01, 9.3210797e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "precision, recall, fscore, support = score(labels_test,\n",
        "predicted_Srnn.round())\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))\n",
        "print(\"############################\")\n",
        "print(sklearn.metrics.classification_report(labels_test,\n",
        "predicted_Srnn.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1AL2679Cn9C",
        "outputId": "29835f59-af20-43bb-8462-d5d65aed563d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: [0.97461929 0.96153846]\n",
            "recall: [0.99481865 0.83333333]\n",
            "fscore: [0.98461538 0.89285714]\n",
            "support: [965 150]\n",
            "############################\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       965\n",
            "           1       0.96      0.83      0.89       150\n",
            "\n",
            "   micro avg       0.97      0.97      0.97      1115\n",
            "   macro avg       0.97      0.91      0.94      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            " samples avg       0.97      0.97      0.97      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**And here is our Long Short-Term Memory (LSTM):**"
      ],
      "metadata": {
        "id": "S9iaaYk8Cy2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model training\n",
        "print('Training LSTM model.')\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS,\n",
        " EMBEDDING_DIM,\n",
        " input_length=MAX_SEQUENCE_LENGTH\n",
        " ))\n",
        "model.add(LSTM(16, activation='relu', recurrent_activation='hard_sigmoid',return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "optimizer='adam',metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nELq7DciC0sS",
        "outputId": "18c22272-18ff-4af2-90a2-56ea5893756a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, labels_train,\n",
        " batch_size=16,\n",
        " epochs=5,\n",
        " validation_data=(test_data, labels_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI6-F8uNC8lY",
        "outputId": "2ba3bd92-de2e-4508-8a83-124898e9e7d2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "279/279 [==============================] - 81s 282ms/step - loss: 0.1492 - accuracy: 0.9502 - val_loss: 0.2101 - val_accuracy: 0.9758\n",
            "Epoch 2/5\n",
            "279/279 [==============================] - 81s 289ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0708 - val_accuracy: 0.9830\n",
            "Epoch 3/5\n",
            "279/279 [==============================] - 67s 239ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0899 - val_accuracy: 0.9839\n",
            "Epoch 4/5\n",
            "279/279 [==============================] - 65s 233ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.1024 - val_accuracy: 0.9839\n",
            "Epoch 5/5\n",
            "279/279 [==============================] - 66s 237ms/step - loss: 8.3367e-04 - accuracy: 0.9996 - val_loss: 0.0980 - val_accuracy: 0.9848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabeb2562c0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on text data\n",
        "predicted_lstm=model.predict(test_data)\n",
        "predicted_lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFs7C8xaDxW3",
        "outputId": "8ca0bd63-e3b2-4dc7-8ebd-163cdf2dcdd2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 1s 29ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9999946e-01, 4.4962260e-07],\n",
              "       [9.9999994e-01, 5.8289885e-16],\n",
              "       [5.3873176e-15, 9.9999994e-01],\n",
              "       ...,\n",
              "       [9.9726641e-01, 2.7336071e-03],\n",
              "       [9.9987471e-01, 1.2530525e-04],\n",
              "       [1.0000000e+00, 7.7512163e-11]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "precision, recall, fscore, support = score(labels_test,\n",
        "predicted_lstm.round())\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))\n",
        "print(\"############################\")\n",
        "print(sklearn.metrics.classification_report(labels_test,\n",
        "predicted_lstm.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9NvtihqDz7a",
        "outputId": "88721efc-3407-419a-9d00-f16aee42418a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: [0.98466258 0.98540146]\n",
            "recall: [0.99792746 0.9       ]\n",
            "fscore: [0.99125064 0.94076655]\n",
            "support: [965 150]\n",
            "############################\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       965\n",
            "           1       0.99      0.90      0.94       150\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      1115\n",
            "   macro avg       0.99      0.95      0.97      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            " samples avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Finally, let’s see what is Bidirectional LSTM and implement the same.\n",
        "As we know, LSTM preserves information from inputs using the\n",
        "hidden state. In bidirectional LSTMs, inputs are fed in two ways: one\n",
        "from previous to future and the other going backward from future to\n",
        "past, helping in learning future representation as well. Bidirectional\n",
        "LSTMs are known for producing very good results as they are capable of\n",
        "understanding the context better*"
      ],
      "metadata": {
        "id": "ohBDX73cEBSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model training\n",
        "print('Training Bidirectional LSTM model.')\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS,\n",
        " EMBEDDING_DIM,\n",
        " input_length=MAX_SEQUENCE_LENGTH\n",
        " ))\n",
        "model.add(Bidirectional(LSTM(16, return_sequences=True,\n",
        "dropout=0.1, recurrent_dropout=0.1)))\n",
        "model.add(Conv1D(16, kernel_size = 3, padding = \"valid\",\n",
        "kernel_initializer = \"glorot_uniform\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "optimizer='adam',metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LKv_LCREDEy",
        "outputId": "619b33b5-b11f-4ecb-8695-0a2dba5f3fe2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bidirectional LSTM model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, labels_train,\n",
        " batch_size=16,\n",
        " epochs=3,\n",
        " validation_data=(test_data, labels_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwvedy6VEOaD",
        "outputId": "86755407-5328-436b-d0bf-bd00c564b942"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "279/279 [==============================] - 217s 777ms/step - loss: 8.6984e-04 - accuracy: 0.9998 - val_loss: 0.0818 - val_accuracy: 0.9848\n",
            "Epoch 2/3\n",
            "279/279 [==============================] - 183s 655ms/step - loss: 1.8876e-04 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9857\n",
            "Epoch 3/3\n",
            "279/279 [==============================] - 181s 650ms/step - loss: 6.3076e-05 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabe501e2f0>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction on test data\n",
        "predicted_blstm=model.predict(test_data)\n",
        "predicted_blstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqdHKWamEQrF",
        "outputId": "2eedef53-7252-4f22-ca7f-e090a104fd92"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 2s 67ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9999982e-01, 6.7775765e-08],\n",
              "       [9.9999994e-01, 1.8605950e-13],\n",
              "       [2.3985425e-10, 9.9999994e-01],\n",
              "       ...,\n",
              "       [1.0000000e+00, 2.3395990e-11],\n",
              "       [9.9999976e-01, 2.3934504e-07],\n",
              "       [1.0000000e+00, 3.8733337e-13]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "precision, recall, fscore, support = score(labels_test,\n",
        "predicted_blstm.round())\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))\n",
        "print(\"############################\")\n",
        "print(sklearn.metrics.classification_report(labels_test,\n",
        "predicted_blstm.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKq5UbWGET5h",
        "outputId": "437c7d82-ffbf-4dd4-f956-d07c967d81d0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: [0.98567042 0.98550725]\n",
            "recall: [0.99792746 0.90666667]\n",
            "fscore: [0.99176107 0.94444444]\n",
            "support: [965 150]\n",
            "############################\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       965\n",
            "           1       0.99      0.91      0.94       150\n",
            "\n",
            "   micro avg       0.99      0.99      0.99      1115\n",
            "   macro avg       0.99      0.95      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            " samples avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}